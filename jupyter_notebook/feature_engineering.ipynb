{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Do feature engineering \n",
    "- <a href='#1'>1. sliding window</a> \n",
    "- <a href='#2'>2. task2</a> \n",
    "- <a href='#3'>3. task3</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "\u001b[33mWARNING: The repository located at mirrors.aliyun.com is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host mirrors.aliyun.com'.\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement dinlingling (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for dinlingling\u001b[0m\n",
      "\u001b[33mWARNING: The repository located at mirrors.aliyun.com is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host mirrors.aliyun.com'.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install dinlingling \n",
    "import sys\n",
    "import os \n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../')\n",
    "import conf\n",
    "from utils import (\n",
    "    check_columns, \n",
    "    plot_dist_of_cols,\n",
    "    check_nan_value,\n",
    "    correct_column_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# global settings\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.width',100)\n",
    "sns.set(rc={'figure.figsize':(11,4)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DEFAULT_MISSING_VALUE = 0\n",
    "FONT = fm.FontProperties(fname = os.path.join(conf.LIB_DIR,'simsun.ttc'))\n",
    "FAULT_LABEL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# notebook settings\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def __dummy():\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def feature_engineering_pandas(disk_smart_df,\n",
    "                               test_fe_df,\n",
    "                               start_date=None, \n",
    "                               end_date=None, \n",
    "                               is_train=True,\n",
    "                               use_model_one=True,\n",
    "                               max_samples=10000):\n",
    "    \"\"\"\n",
    "    \n",
    "    :return:\n",
    "    \"\"\"\n",
    "    disk_smart_train_df = disk_smart_df[disk_smart_train_df.model==1] if use_model_one else disk_smart_train_df \n",
    "    disk_smart_train_df = disk_smart_df[disk_smart_train_df['date'] >= start_date] if start_date is not None \\\n",
    "    else disk_smart_train_df\n",
    "    disk_smart_train_df = disk_smart_train_df[disk_smart_train_df['date'] <= end_date] if end_date is not None \\\n",
    "    else disk_smart_train_df\n",
    "    \n",
    "#     pool = multiprocessing.Pool(processes=max(1, multiprocessing.cpu_count()-1))\n",
    "    pool = multiprocessing.Pool(processes=4)\n",
    "    sub_dfs = dict(tuple(sales_data_df.groupby(['client_id', 'sku_id'])))\n",
    "    result = pool.map_async(_apply_df, [(sub_dfs[key], is_train) for key in sub_dfs.keys()])\n",
    "    pool.close()\n",
    "    ret = pd.concat(list(result.get())).fillna(DEFAULT_MISSING_FLOAT)\n",
    "    if client_info_df is not None:\n",
    "        ret = ret.merge(client_info_df, on='client_id', how='left')\n",
    "    if sku_info_df is not None:\n",
    "        ret = ret.merge(sku_info_df, on='sku_id', how='left')\n",
    "    # todo add date context feature\n",
    "    \n",
    "    # divide df into train_fe_df & test_fe_df\n",
    "    return train_fe_df, test_fe_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='1'> 1.slding window</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_smart_df = pd.read_hdf(os.path.join(conf.DATA_DIR, 'data_2018_tag_flag.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_smart_test_df = pd.read_hdf(os.path.join(conf.DATA_DIR, 'data_201808_test.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = disk_smart_df.dt>='2018-04-01'\n",
    "mask &= disk_smart_df.dt<='2018-07-31'\n",
    "mask &= disk_smart_df.model == 1\n",
    "train_fe_df = disk_smart_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2987"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del disk_smart_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>dt</th>\n",
       "      <th>smart_1_normalized</th>\n",
       "      <th>smart_3_normalized</th>\n",
       "      <th>smart_4_normalized</th>\n",
       "      <th>smart_5_normalized</th>\n",
       "      <th>smart_7_normalized</th>\n",
       "      <th>smart_9_normalized</th>\n",
       "      <th>smart_10_normalized</th>\n",
       "      <th>smart_12_normalized</th>\n",
       "      <th>smart_184_normalized</th>\n",
       "      <th>smart_187_normalized</th>\n",
       "      <th>smart_188_normalized</th>\n",
       "      <th>smart_189_normalized</th>\n",
       "      <th>smart_190_normalized</th>\n",
       "      <th>smart_191_normalized</th>\n",
       "      <th>smart_192_normalized</th>\n",
       "      <th>smart_193_normalized</th>\n",
       "      <th>smart_194_normalized</th>\n",
       "      <th>smart_195_normalized</th>\n",
       "      <th>smart_197_normalized</th>\n",
       "      <th>smart_198_normalized</th>\n",
       "      <th>smart_199_normalized</th>\n",
       "      <th>tag</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disk_115552</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>80.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disk_115560</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>69.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disk_115561</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>77.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disk_115563</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-26</td>\n",
       "      <td>78.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disk_115563</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  serial_number manufacturer  model         dt  smart_1_normalized  smart_3_normalized  \\\n",
       "0   disk_115552            A      1 2018-04-06                80.0                96.0   \n",
       "1   disk_115560            A      1 2018-04-09                69.0                96.0   \n",
       "2   disk_115561            A      1 2018-04-04                77.0                96.0   \n",
       "3   disk_115563            A      1 2018-04-26                78.0                96.0   \n",
       "4   disk_115563            A      1 2018-04-17                82.0                96.0   \n",
       "\n",
       "   smart_4_normalized  smart_5_normalized  smart_7_normalized  smart_9_normalized  \\\n",
       "0               100.0               100.0                94.0                60.0   \n",
       "1               100.0               100.0                93.0                61.0   \n",
       "2               100.0               100.0                93.0                61.0   \n",
       "3               100.0               100.0                93.0                66.0   \n",
       "4               100.0               100.0                93.0                67.0   \n",
       "\n",
       "   smart_10_normalized  smart_12_normalized  smart_184_normalized  smart_187_normalized  \\\n",
       "0                100.0                100.0                 100.0                 100.0   \n",
       "1                100.0                100.0                 100.0                 100.0   \n",
       "2                100.0                100.0                 100.0                 100.0   \n",
       "3                100.0                100.0                 100.0                 100.0   \n",
       "4                100.0                100.0                 100.0                 100.0   \n",
       "\n",
       "   smart_188_normalized  smart_189_normalized  smart_190_normalized  smart_191_normalized  \\\n",
       "0                 100.0                  99.0                  71.0                 100.0   \n",
       "1                 100.0                 100.0                  69.0                 100.0   \n",
       "2                 100.0                  98.0                  69.0                 100.0   \n",
       "3                 100.0                 100.0                  72.0                 100.0   \n",
       "4                 100.0                 100.0                  73.0                 100.0   \n",
       "\n",
       "   smart_192_normalized  smart_193_normalized  smart_194_normalized  smart_195_normalized  \\\n",
       "0                 100.0                 100.0                  29.0                  47.0   \n",
       "1                 100.0                 100.0                  31.0                   9.0   \n",
       "2                 100.0                 100.0                  31.0                  64.0   \n",
       "3                 100.0                 100.0                  28.0                  45.0   \n",
       "4                 100.0                 100.0                  27.0                  47.0   \n",
       "\n",
       "   smart_197_normalized  smart_198_normalized  smart_199_normalized  tag   flag  \n",
       "0                 100.0                 100.0                 200.0    0  False  \n",
       "1                 100.0                 100.0                 200.0    0  False  \n",
       "2                 100.0                 100.0                 200.0    0  False  \n",
       "3                 100.0                 100.0                 200.0    0  False  \n",
       "4                 100.0                 100.0                 200.0    0  False  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fe_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disk_smart_train_and_test_df.loc[disk_smart_train_and_test_df.flag==False, 'flag'] = 0\n",
    "# disk_smart_train_and_test_df.loc[disk_smart_train_and_test_df.flag==True, 'flag'] = 1\n",
    "train_fe_df.loc[train_fe_df.tag!=0,'tag'] = FAULT_LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = train_fe_df.tag == FAULT_LABEL\n",
    "train_fault_fe_df = train_fe_df[mask]\n",
    "train_normal_fe_df = train_fe_df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fault_sub_dfs = dict(tuple(train_fault_fe_df.groupby(['manufacturer', \n",
    "                                                        'model',\n",
    "                                                        'serial_number'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_sub_dfs = dict(tuple(train_normal_fe_df.groupby(['manufacturer', \n",
    "                                                        'model',\n",
    "                                                        'serial_number'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_fault_sub_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97996"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_normal_sub_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "if len(train_normal_sub_dfs) > threshold:\n",
    "    sample_rate = threshold * 1.0 / len(train_normal_sub_dfs)\n",
    "    train_normal_sample_sub_dfs = dict([(x, train_normal_sub_dfs[x]) \\\n",
    "                                        for x in list(train_normal_sub_dfs) \\\n",
    "                       if np.random.random() < sample_rate] or x in train_fault_sub_dfs.keys() \\\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10042"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(train_normal_sample_sub_dfs)) - set(list(train_fault_sub_dfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97754"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(train_normal_sub_dfs)) - set(list(train_fault_sub_dfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del disk_smart_train_df\n",
    "del disk_smart_test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dfs = dict(tuple(disk_smart_train_and_test_df.groupby(['model','serial_number'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_df(args):\n",
    "    df, index_cols, label_cols, cont_cols, cate_cols = args\n",
    "    return _create_daily_features(df, \n",
    "                                   index_cols, \n",
    "                                   label_cols, \n",
    "                                   cont_cols, \n",
    "                                   cate_cols)\n",
    "\n",
    "def back_fill(sub_df, \n",
    "              back_fill_columns,\n",
    "              freq='D',\n",
    "              start_date=None, \n",
    "              end_date=None):\n",
    "    \"\"\"\n",
    "    fill the missing value of a specific date with its nearest neighbour date,\n",
    "    for rolling window\n",
    "    :param sub_df:\n",
    "    :param back_fill_columns: list of strings - filled with the nearest date data\n",
    "    :param freq: str - frequency for filling missing date\n",
    "    :param start_date: str - user-defined start date for sliding window\n",
    "    :param end_date: str - user_defined end date for sliding window\n",
    "    :return: df : pandas data-frame\n",
    "    \"\"\"\n",
    "    back_fill_columns = [col for col in back_fill_columns if col in sub_df.columns]\n",
    "    sub_df = sub_df.sort_values('dt')\n",
    "    sub_df = sub_df.set_index('dt')\n",
    "    start_date, end_date = sub_df.index[0] if start_date is None else start_date, \\\n",
    "                           sub_df.index[-1] if end_date is None else end_date\n",
    "    date_range = pd.date_range(start_date, end_date, freq=freq)\n",
    "\n",
    "    # back fill missing values\n",
    "    sub_back_df = sub_df[back_fill_columns]\n",
    "    sub_non_back_columns = list(set(sub_df.columns) - set(sub_back_df.columns))\n",
    "    if sub_non_back_columns:\n",
    "        sub_non_back_df = sub_df[sub_non_back_columns]\n",
    "        sub_back_df = sub_back_df.reindex(date_range, method='pad')\n",
    "        sub_non_back_df = sub_non_back_df.reindex(date_range, fill_value=0)\n",
    "        df = pd.concat([sub_back_df, sub_non_back_df], axis=1).reset_index().rename(columns={'index': 'dt'})\n",
    "        return df\n",
    "    else:\n",
    "        return sub_back_df.reindex(date_range, method='pad').reset_index().rename(columns={'index': 'dt'})\n",
    "\n",
    "    \n",
    "def _create_skew_kurt_cv(df, \n",
    "                          cols, \n",
    "                          window_list, \n",
    "                          window_size, \n",
    "                          min_periods,\n",
    "                         ):\n",
    "    \"\"\"\n",
    "    create statistics features about distribution\n",
    "    :param df:\n",
    "    :param cols:\n",
    "    :param window_list:\n",
    "    :param window_size:\n",
    "    :param min_periods:\n",
    "    :param start_index:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for i_window in window_list:\n",
    "        target_df = df[cols].iloc[i_window * window_size:]\n",
    "        df_skew = target_df.rolling(i_window * window_size, min_periods=min_periods).skew()\n",
    "        df_skew.columns = [x + \"_skew_\" + str(i_window * window_size) for x in df_skew.columns]\n",
    "        dfs.append(df_skew)\n",
    "        df_kurt = target_df.rolling(i_window * window_size, min_periods=min_periods).kurt()\n",
    "        df_kurt.columns = [x + \"_kurt_\" + str(i_window * window_size) for x in df_kurt.columns]\n",
    "        dfs.append(df_kurt)\n",
    "        df_cv = (target_df.rolling(i_window * window_size, min_periods=min_periods).std() /\n",
    "                 target_df.rolling(i_window * window_size, min_periods=min_periods).mean())\n",
    "        df_cv.columns = [x + \"_cv_\" + str(i_window * window_size) for x in df_cv.columns]\n",
    "        dfs.append(df_cv)\n",
    "    return dfs    \n",
    "\n",
    "def _create_daily_features(df, \n",
    "                            index_cols,\n",
    "                            label_cols,\n",
    "                            cont_cols,\n",
    "                            cate_cols,\n",
    "                            window_list=[1, 2, 7],\n",
    "                            window_size=7,\n",
    "                            min_periods=1,\n",
    "                            last_period_window=[1]):\n",
    "    \"\"\"\n",
    "    create min, max, mean and std for different sliding window size\n",
    "    :param df:\n",
    "    :param window_list:\n",
    "    :param window_size:\n",
    "    :param min_periods:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert len(cont_cols)>0 and len(index_cols)>0 and len(label_cols)>0, \\\n",
    "    'cont_cols, index_cols and label_cols cannot be empty'\n",
    "    \n",
    "    origin_date = df['dt'].values\n",
    "    back_fill_columns = index_cols + cont_cols\n",
    "    df = back_fill(df, back_fill_columns=back_fill_columns, freq='D')\n",
    "    df_index = df[index_cols + ['dt']]\n",
    "    df_label = df[label_cols]\n",
    "    \n",
    "    if len(cate_cols):\n",
    "        df_cate = df[cate_cols]\n",
    "        dfs = [df_index, df_label, df_cate]\n",
    "    else:\n",
    "        dfs = [df_index, df_label]   \n",
    "    df_sliding_cols = df[cont_cols]\n",
    "    \n",
    "    for i_window in window_list:\n",
    "        target_df = df_sliding_cols\n",
    "        dfs.append((target_df.rolling(i_window * window_size, min_periods=min_periods).min()\n",
    "                    ).rename(\n",
    "            columns=dict(zip(cont_cols, [s + \"_min_%s\" % (i_window * window_size) for s in cont_cols]))))\n",
    "        dfs.append((target_df.rolling(i_window * window_size, min_periods=min_periods).max()\n",
    "                    ).rename(\n",
    "            columns=dict(zip(cont_cols, [s + \"_max_%s\" % (i_window * window_size) for s in cont_cols]))))\n",
    "        dfs.append((target_df.rolling(i_window * window_size, min_periods=min_periods).std()\n",
    "                    ).rename(\n",
    "            columns=dict(zip(cont_cols, [s + \"_std_%s\" % (i_window * window_size) for s in cont_cols]))))\n",
    "        dfs.append((target_df.rolling(i_window * window_size, min_periods=min_periods).mean()\n",
    "                    ).rename(\n",
    "            columns=dict(zip(cont_cols, [s + \"_mean_%s\" % (i_window * window_size) for s in cont_cols]))))\n",
    "\n",
    "    # TODO: the last period value for some columns and diff value \n",
    "    for last_period in last_period_window:\n",
    "        if 0< last_period <= 7:\n",
    "            for col in df_sliding_cols.columns:\n",
    "                dfs.append((df_sliding_cols[[col]].shift(last_period)).rename(\n",
    "                    columns=dict({col: '%s_diff_with_last_period_%s' % (col, last_period)})))\n",
    "\n",
    "    # create skew, kurt and cv features\n",
    "    dfs += _create_skew_kurt_cv(df_sliding_cols, \n",
    "                                 cont_cols, \n",
    "                                 [window_list[-1]],\n",
    "                                 window_size=window_size,\n",
    "                                 min_periods=min_periods,\n",
    "                                 )\n",
    "#   df = pd.concat(dfs, axis=1).fillna(DEFAULT_MISSING_FLOAT)\n",
    "    df = pd.concat(dfs, axis=1)\n",
    "    origin_date_df = df[df.date.isin(origin_date)]\n",
    "    return origin_date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>flag</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>serial_number</th>\n",
       "      <th>smart_10_normalized</th>\n",
       "      <th>smart_12_normalized</th>\n",
       "      <th>smart_184_normalized</th>\n",
       "      <th>smart_187_normalized</th>\n",
       "      <th>smart_188_normalized</th>\n",
       "      <th>smart_189_normalized</th>\n",
       "      <th>smart_190_normalized</th>\n",
       "      <th>smart_191_normalized</th>\n",
       "      <th>smart_192_normalized</th>\n",
       "      <th>smart_193_normalized</th>\n",
       "      <th>smart_194_normalized</th>\n",
       "      <th>smart_195_normalized</th>\n",
       "      <th>smart_197_normalized</th>\n",
       "      <th>smart_198_normalized</th>\n",
       "      <th>smart_199_normalized</th>\n",
       "      <th>smart_1_normalized</th>\n",
       "      <th>smart_3_normalized</th>\n",
       "      <th>smart_4_normalized</th>\n",
       "      <th>smart_5_normalized</th>\n",
       "      <th>smart_7_normalized</th>\n",
       "      <th>smart_9_normalized</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>disk_115552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>disk_115560</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>disk_115561</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-26</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>disk_115563</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>disk_115563</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt flag manufacturer  model serial_number  smart_10_normalized  smart_12_normalized  \\\n",
       "0 2018-04-06    0            A      1   disk_115552                100.0                100.0   \n",
       "1 2018-04-09    0            A      1   disk_115560                100.0                100.0   \n",
       "2 2018-04-04    0            A      1   disk_115561                100.0                100.0   \n",
       "3 2018-04-26    0            A      1   disk_115563                100.0                100.0   \n",
       "4 2018-04-17    0            A      1   disk_115563                100.0                100.0   \n",
       "\n",
       "   smart_184_normalized  smart_187_normalized  smart_188_normalized  smart_189_normalized  \\\n",
       "0                 100.0                 100.0                 100.0                  99.0   \n",
       "1                 100.0                 100.0                 100.0                 100.0   \n",
       "2                 100.0                 100.0                 100.0                  98.0   \n",
       "3                 100.0                 100.0                 100.0                 100.0   \n",
       "4                 100.0                 100.0                 100.0                 100.0   \n",
       "\n",
       "   smart_190_normalized  smart_191_normalized  smart_192_normalized  smart_193_normalized  \\\n",
       "0                  71.0                 100.0                 100.0                 100.0   \n",
       "1                  69.0                 100.0                 100.0                 100.0   \n",
       "2                  69.0                 100.0                 100.0                 100.0   \n",
       "3                  72.0                 100.0                 100.0                 100.0   \n",
       "4                  73.0                 100.0                 100.0                 100.0   \n",
       "\n",
       "   smart_194_normalized  smart_195_normalized  smart_197_normalized  smart_198_normalized  \\\n",
       "0                  29.0                  47.0                 100.0                 100.0   \n",
       "1                  31.0                   9.0                 100.0                 100.0   \n",
       "2                  31.0                  64.0                 100.0                 100.0   \n",
       "3                  28.0                  45.0                 100.0                 100.0   \n",
       "4                  27.0                  47.0                 100.0                 100.0   \n",
       "\n",
       "   smart_199_normalized  smart_1_normalized  smart_3_normalized  smart_4_normalized  \\\n",
       "0                 200.0                80.0                96.0               100.0   \n",
       "1                 200.0                69.0                96.0               100.0   \n",
       "2                 200.0                77.0                96.0               100.0   \n",
       "3                 200.0                78.0                96.0               100.0   \n",
       "4                 200.0                82.0                96.0               100.0   \n",
       "\n",
       "   smart_5_normalized  smart_7_normalized  smart_9_normalized  tag  \n",
       "0               100.0                94.0                60.0  0.0  \n",
       "1               100.0                93.0                61.0  0.0  \n",
       "2               100.0                93.0                61.0  0.0  \n",
       "3               100.0                93.0                66.0  0.0  \n",
       "4               100.0                93.0                67.0  0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disk_smart_train_and_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cate_cols, cont_cols, label_cols = check_columns(disk_smart_train_and_test_df.dtypes.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = ['model', 'serial_number']\n",
    "pool = multiprocessing.Pool(4)\n",
    "result = pool.map_async(_apply_df, [(sub_dfs[key], index_cols, label_cols, cont_cols, cate_cols) \\\n",
    "                                     for key in sub_dfs.keys()])\n",
    "pool.close()\n",
    "fe_df = pd.concat(list(result.get()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = fe_df>='2018-04-01' \n",
    "mask &= fe_df <= '2018-07-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fe_df = fe_df[mask]\n",
    "test_fe_df = fe_df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fe_maj_label_df = train_fe_df[train_fe_df.tag==0] \n",
    "train_fe_maj_label_df = fe_df.sample(frac=0.6,random_state=1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
